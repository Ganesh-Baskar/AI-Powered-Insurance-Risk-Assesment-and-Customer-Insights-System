{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7218724b-60b9-4827-9cc0-0d90bff2a0fd",
   "metadata": {},
   "source": [
    "# üß† Multilingual Insurance Document Translator\n",
    "Goal: Translate a single English insurance document (PDF) into multiple languages in one go.\n",
    "‚úÖ Features\n",
    "\n",
    "üìÑ Extract text from PDF.\n",
    "\n",
    "üåç Select multiple target languages.\n",
    "\n",
    "ü§ñ Translate using Hugging Face Transformers.\n",
    "\n",
    "üìù Generate one translated PDF per language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0606252-de82-4331-afae-0f45af195067",
   "metadata": {},
   "source": [
    "# 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db77d37-7cb7-415d-8566-ae31a099f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.5/2.6 MB 3.6 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.0/2.6 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.1/2.6 MB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 3.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [48 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Roaming\\Python\\Python313\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "      main()\n",
      "      ~~~~^^\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Roaming\\Python\\Python313\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "      json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                               ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Roaming\\Python\\Python313\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Local\\Temp\\pip-build-env-1a9gm_zs\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 331, in get_requires_for_build_wheel\n",
      "      return self._get_build_requires(config_settings, requirements=[])\n",
      "             ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Local\\Temp\\pip-build-env-1a9gm_zs\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 301, in _get_build_requires\n",
      "      self.run_setup()\n",
      "      ~~~~~~~~~~~~~~^^\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Local\\Temp\\pip-build-env-1a9gm_zs\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "      ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\Ganesh Baskar\\AppData\\Local\\Temp\\pip-build-env-1a9gm_zs\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
      "      exec(code, locals())\n",
      "      ~~~~^^^^^^^^^^^^^^^^\n",
      "    File \"<string>\", line 128, in <module>\n",
      "    File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 414, in check_call\n",
      "      retcode = call(*popenargs, **kwargs)\n",
      "    File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 395, in call\n",
      "      with Popen(*popenargs, **kwargs) as p:\n",
      "           ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 1036, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "      ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          pass_fds, cwd, env,\n",
      "                          ^^^^^^^^^^^^^^^^^^^\n",
      "      ...<5 lines>...\n",
      "                          gid, gids, uid, umask,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                          start_new_session, process_group)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Program Files\\Python313\\Lib\\subprocess.py\", line 1548, in _execute_child\n",
      "      hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                         ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                               # no special security\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^\n",
      "      ...<4 lines>...\n",
      "                               cwd,\n",
      "                               ^^^^\n",
      "                               startupinfo)\n",
      "                               ^^^^^^^^^^^^\n",
      "  FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch sentencepiece fpdf pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc7556-e3ee-4945-bfc1-4ec16893f049",
   "metadata": {},
   "source": [
    "# 2. Script to Translate English PDF to Multiple Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10133d33-acbf-4535-a049-f62c912d76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.3-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "   ---------------------------------------- 0.0/18.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/18.7 MB 3.1 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.6/18.7 MB 3.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/18.7 MB 3.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.1/18.7 MB 3.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 4.2/18.7 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.7/18.7 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 5.5/18.7 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 6.3/18.7 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.8/18.7 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 7.9/18.7 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 8.7/18.7 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 9.4/18.7 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 10.5/18.7 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 11.3/18.7 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 12.3/18.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 13.4/18.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 14.2/18.7 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 15.2/18.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 16.3/18.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.0/18.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.1/18.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.6/18.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.7/18.7 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f007caff-c38d-4834-ba7f-f9ead30808a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (pyproject.toml): started\n",
      "  Building wheel for fpdf (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40769 sha256=61e5158af898f3b3de2dd7f6bc72418ba99e3a95ea1acb2e52c872c24c826df0\n",
      "  Stored in directory: c:\\users\\ganesh baskar\\appdata\\local\\pip\\cache\\wheels\\aa\\da\\11\\a3189f34ddc13c26a2d0f329eac46b728c7f31c39e4dc26243\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4fde70e-8ee4-4e49-b07b-5080547a2d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.12.14)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\program files\\python313\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (pyproject.toml): started\n",
      "  Building wheel for googletrans (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17516 sha256=e5defdefe21eaf1ff2586b599082cdbf37ad132d01197058bd2982b9542e3345\n",
      "  Stored in directory: c:\\users\\ganesh baskar\\appdata\\local\\pip\\cache\\wheels\\79\\4e\\93\\807caa936897ff772ae263e9f39eb1d4878ef21e2d4c45a2a3\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "\n",
      "   ------- --------------------------------  2/11 [hpack]\n",
      "   ---------- -----------------------------  3/11 [h11]\n",
      "   -------------- -------------------------  4/11 [chardet]\n",
      "   -------------- -------------------------  4/11 [chardet]\n",
      "   ------------------ ---------------------  5/11 [idna]\n",
      "   --------------------- ------------------  6/11 [hstspreload]\n",
      "   ------------------------- --------------  7/11 [h2]\n",
      "   ----------------------------- ----------  8/11 [httpcore]\n",
      "   -------------------------------- -------  9/11 [httpx]\n",
      "   ---------------------------------------- 11/11 [googletrans]\n",
      "\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.3.4 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22a773a-35a1-4573-b231-ea527402c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting legacy-cgi\n",
      "  Downloading legacy_cgi-2.6.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading legacy_cgi-2.6.3-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: legacy-cgi\n",
      "Successfully installed legacy-cgi-2.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install legacy-cgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b05f909-7169-4a22-9a69-ba9b72e0779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Translating to Tamil...\n",
      "üîÅ Translating to Hindi...\n",
      "üîÅ Translating to Malayalam...\n",
      "üîÅ Translating to Telugu...\n",
      "üîÅ Translating to Bengali...\n",
      "üîÅ Translating to Gujarati...\n",
      "‚úÖ PDF saved for Tamil: Translated_Insurance_Policy_Tamil.pdf\n",
      "‚úÖ PDF saved for Hindi: Translated_Insurance_Policy_Hindi.pdf\n",
      "‚úÖ PDF saved for Malayalam: Translated_Insurance_Policy_Malayalam.pdf\n",
      "‚úÖ PDF saved for Telugu: Translated_Insurance_Policy_Telugu.pdf\n",
      "‚úÖ PDF saved for Bengali: Translated_Insurance_Policy_Bengali.pdf\n",
      "‚úÖ PDF saved for Gujarati: Translated_Insurance_Policy_Gujarati.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from fpdf import FPDF\n",
    "import textwrap\n",
    "from googletrans import Translator\n",
    "\n",
    "# Constants\n",
    "FONT_PATH = \"C:/Users/Ganesh Baskar/OneDrive/Documents/font/NotoSans-Regular.ttf\"\n",
    "FONT_FAMILY = \"NotoSans\"\n",
    "DEFAULT_LANGUAGE = \"Tamil\"\n",
    "\n",
    "# Define supported languages with Google Translate codes\n",
    "SUPPORTED_LANGUAGES = {\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Telugu\": \"te\",\n",
    "    \"Gujarati\": \"gu\",\n",
    "    \"Kannada\": \"kn\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Punjabi\": \"pa\",\n",
    "    \"Marathi\": \"mr\",\n",
    "    \"Malayalam\": \"ml\",\n",
    "    \"Urdu\": \"ur\",\n",
    "    \"Odia\": \"or\"\n",
    "}\n",
    "\n",
    "# Step 1: Extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "# Step 2: Translate text to multiple languages\n",
    "def translate_text(text, target_languages):\n",
    "    translator = Translator()\n",
    "    translations = {}\n",
    "    for language in target_languages:\n",
    "        try:\n",
    "            lang_code = SUPPORTED_LANGUAGES[language]\n",
    "            print(f\"üîÅ Translating to {language}...\")\n",
    "            translated = translator.translate(text, dest=lang_code)\n",
    "            translations[language] = translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error translating to {language}: {e}\")\n",
    "    return translations\n",
    "\n",
    "# Step 3: PDF generator that preserves alignment\n",
    "class UnicodePDF(FPDF):\n",
    "    def __init__(self, font_path, font_family, title=\"\"):\n",
    "        super().__init__()\n",
    "        if not os.path.isfile(font_path):\n",
    "            raise RuntimeError(f\"‚ùå Font file not found: {font_path}\")\n",
    "        self.font_family = font_family\n",
    "        self.title = title  # Set title before add_page\n",
    "        self.add_font(font_family, '', font_path, uni=True)\n",
    "        self.add_page()\n",
    "        self.set_font(font_family, '', 12)\n",
    "        self.set_left_margin(10)\n",
    "        self.set_right_margin(10)\n",
    "\n",
    "    def header(self):\n",
    "        self.set_font(self.font_family, '', 16)\n",
    "        self.cell(0, 10, self.title, ln=True, align='C')\n",
    "        self.ln(10)\n",
    "        self.set_font(self.font_family, '', 12)\n",
    "\n",
    "    def add_multiline_text(self, text):\n",
    "        for paragraph in text.split(\"\\n\"):\n",
    "            wrapped = textwrap.fill(paragraph.strip(), width=90)\n",
    "            self.multi_cell(0, 8, wrapped)\n",
    "            self.ln(2)\n",
    "\n",
    "    def save(self, output_path):\n",
    "        self.output(output_path)\n",
    "\n",
    "# Step 4: Create the translated PDF\n",
    "def create_unicode_pdf(translated_text, language, output_path):\n",
    "    try:\n",
    "        pdf = UnicodePDF(FONT_PATH, FONT_FAMILY, f\"Translated Insurance Policy - {language}\")\n",
    "        pdf.add_multiline_text(translated_text)\n",
    "        pdf.save(output_path)\n",
    "        print(f\"‚úÖ PDF saved for {language}: {output_path}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Step 5: Orchestrate the process\n",
    "def main(pdf_path, selected_languages):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    translations = translate_text(text, selected_languages)\n",
    "    for language, translated_text in translations.items():\n",
    "        output_path = f\"Translated_Insurance_Policy_{language}.pdf\"\n",
    "        create_unicode_pdf(translated_text, language, output_path)\n",
    "\n",
    "# Step 6: Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    selected_languages = [\"Tamil\",\"Hindi\", \"Malayalam\", \"Telugu\",\"Bengali\",\"Gujarati\"] \n",
    "    valid_languages = [lang for lang in selected_languages if lang in SUPPORTED_LANGUAGES]\n",
    "\n",
    "    if valid_languages:\n",
    "        pdf_path = \"C:/Users/Ganesh Baskar/OneDrive/Documents/Translation_and_Summarization/Health_Insurance_Policy.pdf\"\n",
    "        main(pdf_path, valid_languages)\n",
    "    else:\n",
    "        print(\"‚ùå No valid languages selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc704b5-028d-48c1-bf85-0e99c845df2b",
   "metadata": {},
   "source": [
    "\n",
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9734e8b1-be63-438c-843d-9b7998a9e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ganesh\n",
      "[nltk_data]     Baskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Translating to Hindi...\n",
      "üîÅ Translating to Tamil...\n",
      "üîÅ Translating to Telugu...\n",
      "‚úÖ PDF saved for Hindi: Translated_Insurance_Policy_Hindi.pdf\n",
      "üü¶ BLEU Score for Hindi: 0.0022\n",
      "‚úÖ PDF saved for Tamil: Translated_Insurance_Policy_Tamil.pdf\n",
      "üü¶ BLEU Score for Tamil: 0.0027\n",
      "‚úÖ PDF saved for Telugu: Translated_Insurance_Policy_Telugu.pdf\n",
      "üü¶ BLEU Score for Telugu: 0.0026\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from fpdf import FPDF\n",
    "import textwrap\n",
    "from googletrans import Translator\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download required tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Constants\n",
    "FONT_PATH = \"C:/Users/Ganesh Baskar/OneDrive/Documents/font/NotoSans-Regular.ttf\"\n",
    "FONT_FAMILY = \"NotoSans\"\n",
    "DEFAULT_LANGUAGE = \"Hindi\"\n",
    "\n",
    "# Supported languages\n",
    "SUPPORTED_LANGUAGES = {\n",
    "    \"Hindi\": \"hi\",\n",
    "    \"Tamil\": \"ta\",\n",
    "    \"Telugu\": \"te\",\n",
    "    \"Gujarati\": \"gu\",\n",
    "    \"Kannada\": \"kn\",\n",
    "    \"Bengali\": \"bn\",\n",
    "    \"Punjabi\": \"pa\",\n",
    "    \"Marathi\": \"mr\",\n",
    "    \"Malayalam\": \"ml\",\n",
    "    \"Urdu\": \"ur\",\n",
    "    \"Odia\": \"or\"\n",
    "}\n",
    "\n",
    "# Reference translations for BLEU score evaluation\n",
    "REFERENCE_TRANSLATIONS = {\n",
    "    \"Hindi\": \"‡§Ø‡§π ‡§è‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¨‡•Ä‡§Æ‡§æ ‡§™‡•â‡§≤‡§ø‡§∏‡•Ä ‡§π‡•à‡•§\",\n",
    "    \"Tamil\": \"‡Æá‡Æ§‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡Æö‡ØÅ‡Æï‡Ææ‡Æ§‡Ææ‡Æ∞ ‡Æï‡Ææ‡Æ™‡Øç‡Æ™‡ØÄ‡Æü‡Øç‡Æü‡ØÅ ‡Æï‡Øä‡Æ≥‡Øç‡Æï‡Øà.\",\n",
    "    \"Telugu\": \"‡∞á‡∞¶‡∞ø ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞¨‡±Ä‡∞Æ‡∞æ ‡∞™‡∞æ‡∞≤‡∞∏‡±Ä.\"\n",
    "    # Add more human reference translations here as needed\n",
    "}\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "# Step 2: Translate text\n",
    "def translate_text(text, target_languages):\n",
    "    translator = Translator()\n",
    "    translations = {}\n",
    "    for language in target_languages:\n",
    "        try:\n",
    "            lang_code = SUPPORTED_LANGUAGES[language]\n",
    "            print(f\"üîÅ Translating to {language}...\")\n",
    "            translated = translator.translate(text, dest=lang_code)\n",
    "            translations[language] = translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error translating to {language}: {e}\")\n",
    "    return translations\n",
    "\n",
    "# Step 3: Unicode PDF generator\n",
    "class UnicodePDF(FPDF):\n",
    "    def __init__(self, font_path, font_family, title=\"\"):\n",
    "        super().__init__()\n",
    "        if not os.path.isfile(font_path):\n",
    "            raise RuntimeError(f\"‚ùå Font file not found: {font_path}\")\n",
    "        self.font_family = font_family\n",
    "        self.title = title\n",
    "        self.add_font(font_family, '', font_path, uni=True)\n",
    "        self.add_page()\n",
    "        self.set_font(font_family, '', 12)\n",
    "        self.set_left_margin(10)\n",
    "        self.set_right_margin(10)\n",
    "\n",
    "    def header(self):\n",
    "        self.set_font(self.font_family, '', 16)\n",
    "        self.cell(0, 10, self.title, ln=True, align='C')\n",
    "        self.ln(10)\n",
    "        self.set_font(self.font_family, '', 12)\n",
    "\n",
    "    def add_multiline_text(self, text):\n",
    "        for paragraph in text.split(\"\\n\"):\n",
    "            wrapped = textwrap.fill(paragraph.strip(), width=90)\n",
    "            self.multi_cell(0, 8, wrapped)\n",
    "            self.ln(2)\n",
    "\n",
    "    def save(self, output_path):\n",
    "        self.output(output_path)\n",
    "\n",
    "# Step 4: Save translated PDF\n",
    "def create_unicode_pdf(translated_text, language, output_path):\n",
    "    try:\n",
    "        pdf = UnicodePDF(FONT_PATH, FONT_FAMILY, f\"Translated Insurance Policy - {language}\")\n",
    "        pdf.add_multiline_text(translated_text)\n",
    "        pdf.save(output_path)\n",
    "        print(f\"‚úÖ PDF saved for {language}: {output_path}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Step 5: Compute BLEU Score\n",
    "def compute_bleu(candidate_text, reference_text):\n",
    "    candidate_tokens = word_tokenize(candidate_text)\n",
    "    reference_tokens = [word_tokenize(reference_text)]\n",
    "    score = sentence_bleu(reference_tokens, candidate_tokens,\n",
    "                          weights=(0.25, 0.25, 0.25, 0.25),\n",
    "                          smoothing_function=SmoothingFunction().method4)\n",
    "    return score\n",
    "\n",
    "# Step 6: Main orchestrator\n",
    "def main(pdf_path, selected_languages):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    translations = translate_text(text, selected_languages)\n",
    "    \n",
    "    for language, translated_text in translations.items():\n",
    "        output_path = f\"Translated_Insurance_Policy_{language}.pdf\"\n",
    "        create_unicode_pdf(translated_text, language, output_path)\n",
    "\n",
    "        # BLEU score evaluation\n",
    "        reference_text = REFERENCE_TRANSLATIONS.get(language)\n",
    "        if reference_text:\n",
    "            bleu_score = compute_bleu(translated_text, reference_text)\n",
    "            print(f\"üü¶ BLEU Score for {language}: {bleu_score:.4f}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No reference translation found for {language}. Skipping BLEU score.\")\n",
    "\n",
    "# Step 7: Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"]  # Choose from SUPPORTED_LANGUAGES\n",
    "    valid_languages = [lang for lang in selected_languages if lang in SUPPORTED_LANGUAGES]\n",
    "\n",
    "    if valid_languages:\n",
    "        pdf_path = \"C:/Users/Ganesh Baskar/OneDrive/Documents/Translation_and_Summarization/Health_Insurance_Policy.pdf\"\n",
    "        main(pdf_path, valid_languages)\n",
    "    else:\n",
    "        print(\"‚ùå No valid languages selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd410e6c-5d51-410f-98ea-53c0abac24b4",
   "metadata": {},
   "source": [
    "# ROUGE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2073ca49-860a-4e0c-bc8b-f4a529820372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\ganesh baskar\\appdata\\roaming\\python\\python313\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ganesh baskar\\appdata\\roaming\\python\\python313\\site-packages (from rouge_score) (2.2.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\program files\\python313\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\ganesh baskar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\ganesh baskar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ganesh baskar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ganesh baskar\\appdata\\roaming\\python\\python313\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python313\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml): started\n",
      "  Building wheel for rouge_score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25027 sha256=fc16ec450b67bc3c32b12c25bd9136adf8d54a23ba80c3a2d7b9c23ea67446c1\n",
      "  Stored in directory: c:\\users\\ganesh baskar\\appdata\\local\\pip\\cache\\wheels\\44\\af\\da\\5ffc433e2786f0b1a9c6f458d5fb8f611d8eb332387f18698f\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "\n",
      "   ---------------------------------------- 0/2 [absl-py]\n",
      "   ---------------------------------------- 0/2 [absl-py]\n",
      "   -------------------- ------------------- 1/2 [rouge_score]\n",
      "   ---------------------------------------- 2/2 [rouge_score]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f39a7a8-eb84-454c-9a86-eb7aa4fc0d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ganesh\n",
      "[nltk_data]     Baskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Translating to Hindi...\n",
      "üîÅ Translating to Tamil...\n",
      "üîÅ Translating to Telugu...\n",
      "‚úÖ PDF saved for Hindi: Translated_Insurance_Policy_Hindi.pdf\n",
      "üü• ROUGE Scores for Hindi:\n",
      "   ROUGE1: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   ROUGE2: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   ROUGEL: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "‚úÖ PDF saved for Tamil: Translated_Insurance_Policy_Tamil.pdf\n",
      "üü• ROUGE Scores for Tamil:\n",
      "   ROUGE1: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   ROUGE2: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   ROUGEL: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "‚úÖ PDF saved for Telugu: Translated_Insurance_Policy_Telugu.pdf\n",
      "üü• ROUGE Scores for Telugu:\n",
      "   ROUGE1: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   ROUGE2: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   ROUGEL: Precision=0.0000, Recall=0.0000, F1=0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from fpdf import FPDF\n",
    "import textwrap\n",
    "from googletrans import Translator\n",
    "from rouge_score import rouge_scorer\n",
    "import nltk\n",
    "\n",
    "# Download required tokenizer (for future use if needed)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# =========================\n",
    "# üîß Configuration Settings\n",
    "# =========================\n",
    "FONT_PATH = r\"C:\\Users\\Ganesh Baskar\\OneDrive\\Documents\\font\\NotoSans-Regular.ttf\"\n",
    "FONT_FAMILY = \"NotoSans\"\n",
    "DEFAULT_LANGUAGE = \"Hindi\"\n",
    "PDF_INPUT_PATH = r\"C:\\Users\\Ganesh Baskar\\OneDrive\\Documents\\Translation_and_Summarization\\Health_Insurance_Policy.pdf\"\n",
    "\n",
    "SUPPORTED_LANGUAGES = {\n",
    "    \"Hindi\": \"hi\", \"Tamil\": \"ta\", \"Telugu\": \"te\", \"Gujarati\": \"gu\",\n",
    "    \"Kannada\": \"kn\", \"Bengali\": \"bn\", \"Punjabi\": \"pa\", \"Marathi\": \"mr\",\n",
    "    \"Malayalam\": \"ml\", \"Urdu\": \"ur\", \"Odia\": \"or\"\n",
    "}\n",
    "\n",
    "REFERENCE_TRANSLATIONS = {\n",
    "    \"Hindi\": \"‡§Ø‡§π ‡§è‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¨‡•Ä‡§Æ‡§æ ‡§™‡•â‡§≤‡§ø‡§∏‡•Ä ‡§π‡•à‡•§\",\n",
    "    \"Tamil\": \"‡Æá‡Æ§‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡Æö‡ØÅ‡Æï‡Ææ‡Æ§‡Ææ‡Æ∞ ‡Æï‡Ææ‡Æ™‡Øç‡Æ™‡ØÄ‡Æü‡Øç‡Æü‡ØÅ ‡Æï‡Øä‡Æ≥‡Øç‡Æï‡Øà.\",\n",
    "    \"Telugu\": \"‡∞á‡∞¶‡∞ø ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞¨‡±Ä‡∞Æ‡∞æ ‡∞™‡∞æ‡∞≤‡∞∏‡±Ä.\"\n",
    "    # Add more reference translations as needed\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# üìÑ Step 1: Extract Text\n",
    "# =========================\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        return \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to extract text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# =========================\n",
    "# üåê Step 2: Translate Text\n",
    "# =========================\n",
    "def translate_text(text, target_languages):\n",
    "    translator = Translator()\n",
    "    translations = {}\n",
    "    for language in target_languages:\n",
    "        lang_code = SUPPORTED_LANGUAGES.get(language)\n",
    "        if not lang_code:\n",
    "            print(f\"‚ö†Ô∏è Unsupported language: {language}\")\n",
    "            continue\n",
    "        try:\n",
    "            print(f\"üîÅ Translating to {language}...\")\n",
    "            translated = translator.translate(text, dest=lang_code)\n",
    "            translations[language] = translated.text\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error translating to {language}: {e}\")\n",
    "    return translations\n",
    "\n",
    "# =========================\n",
    "# üñ® Step 3: PDF Generator\n",
    "# =========================\n",
    "class UnicodePDF(FPDF):\n",
    "    def __init__(self, font_path, font_family, title=\"\"):\n",
    "        super().__init__()\n",
    "        if not os.path.isfile(font_path):\n",
    "            raise RuntimeError(f\"‚ùå Font file not found: {font_path}\")\n",
    "        self.font_family = font_family\n",
    "        self.title = title\n",
    "        self.add_font(font_family, '', font_path, uni=True)\n",
    "        self.add_page()\n",
    "        self.set_font(font_family, '', 12)\n",
    "        self.set_margins(10, 10, 10)\n",
    "\n",
    "    def header(self):\n",
    "        self.set_font(self.font_family, '', 16)\n",
    "        self.cell(0, 10, self.title, ln=True, align='C')\n",
    "        self.ln(10)\n",
    "        self.set_font(self.font_family, '', 12)\n",
    "\n",
    "    def add_multiline_text(self, text):\n",
    "        for paragraph in text.split(\"\\n\"):\n",
    "            wrapped = textwrap.fill(paragraph.strip(), width=90)\n",
    "            self.multi_cell(0, 8, wrapped)\n",
    "            self.ln(2)\n",
    "\n",
    "    def save(self, output_path):\n",
    "        self.output(output_path)\n",
    "\n",
    "# =========================\n",
    "# üì§ Step 4: Save PDF\n",
    "# =========================\n",
    "def create_translated_pdf(text, language):\n",
    "    output_filename = f\"Translated_Insurance_Policy_{language}.pdf\"\n",
    "    try:\n",
    "        pdf = UnicodePDF(FONT_PATH, FONT_FAMILY, f\"Translated Insurance Policy - {language}\")\n",
    "        pdf.add_multiline_text(text)\n",
    "        pdf.save(output_filename)\n",
    "        print(f\"‚úÖ PDF saved for {language}: {output_filename}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# =========================\n",
    "# üü• Step 5: ROUGE Score\n",
    "# =========================\n",
    "def compute_rouge(candidate_text, reference_text):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    return scorer.score(reference_text, candidate_text)\n",
    "\n",
    "# =========================\n",
    "# üöÄ Step 6: Main Workflow\n",
    "# =========================\n",
    "def main(pdf_path, selected_languages):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    if not text:\n",
    "        print(\"‚ùå No text extracted from PDF.\")\n",
    "        return\n",
    "\n",
    "    translations = translate_text(text, selected_languages)\n",
    "    for language, translated_text in translations.items():\n",
    "        create_translated_pdf(translated_text, language)\n",
    "\n",
    "        # ROUGE score evaluation\n",
    "        reference_text = REFERENCE_TRANSLATIONS.get(language)\n",
    "        if reference_text:\n",
    "            rouge_scores = compute_rouge(translated_text, reference_text)\n",
    "            print(f\"üü• ROUGE Scores for {language}:\")\n",
    "            for metric, score in rouge_scores.items():\n",
    "                print(f\"   {metric.upper()}: Precision={score.precision:.4f}, Recall={score.recall:.4f}, F1={score.fmeasure:.4f}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No reference translation found for {language}. Skipping ROUGE score.\")\n",
    "\n",
    "# =========================\n",
    "# üß™ Step 7: Run Script\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    selected_languages = [\"Hindi\", \"Tamil\", \"Telugu\"]\n",
    "    valid_languages = [lang for lang in selected_languages if lang in SUPPORTED_LANGUAGES]\n",
    "\n",
    "    if valid_languages:\n",
    "        main(PDF_INPUT_PATH, valid_languages)\n",
    "    else:\n",
    "        print(\"‚ùå No valid languages selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ec4d6-2a86-42cc-b0f1-88cb8287266b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
